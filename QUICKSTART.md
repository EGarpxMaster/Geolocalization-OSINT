# ğŸ¯ GUÃA RÃPIDA: Fine-Tuning GRATUITO y Open Source

## âš¡ Quick Start (3 pasos)

### 1ï¸âƒ£ Obtener ImÃ¡genes (GRATIS)

**OpciÃ³n A: MinerÃ­a AutomÃ¡tica** (Recomendado)
```powershell
# Wikimedia Commons (sin registro)
python data_mining.py --mode city --city "Puebla" --images 10

# Pexels (registro gratis en 2 min)
# 1. Ir a https://www.pexels.com/api/
# 2. Crear cuenta gratis
# 3. Copiar API key
$env:PEXELS_API_KEY = "tu_key_aqui"
python data_mining.py --mode all --images 5 --limit 10
```

**OpciÃ³n B: Tus Propias Fotos**
```powershell
# Importar una foto
python manual_image_import.py --file "foto_puebla.jpg" --city "Puebla"

# Importar carpeta completa
python manual_image_import.py --folder "mis_fotos/cdmx" --city "Ciudad de MÃ©xico"
```

### 2ï¸âƒ£ Anotar Manualmente
```powershell
streamlit run annotation_tool.py
```

**Meta:** 50-100 imÃ¡genes anotadas (30 minutos aprox)

### 3ï¸âƒ£ Fine-Tuning
```powershell
# Entrenar modelo mejorado
python finetune_model.py --epochs 5

# Regenerar embeddings
python build_model.py

# Probar resultados
streamlit run Geolocalizador.py
```

---

## ğŸ“Š Resultados Esperados

| MÃ©trica | Antes | DespuÃ©s |
|---------|-------|---------|
| **Top-1 Confianza** | 1-5% | 15-40% |
| **Top-3 Confianza** | 5-15% | 40-70% |
| **PrecisiÃ³n** | ~20-30% | ~50-70% |

**Ejemplo Real:**
- Antes: Taxco 1.66%, Cuernavaca 1.60%, San Miguel 1.59%
- DespuÃ©s: Taxco 28%, Cuernavaca 22%, San Miguel 18%

---

## ğŸ” Fuentes de Datos (100% Gratis)

### 1. Wikimedia Commons âœ…
- **Costo:** $0 - Sin lÃ­mites
- **Registro:** No requerido
- **Calidad:** Alta (fotos de Wikipedia)
- **GeolocalizaciÃ³n:** Parcial
- **Licencia:** Creative Commons

### 2. Pexels âœ…
- **Costo:** $0
- **Registro:** 2 minutos (gratis)
- **LÃ­mite:** 200 requests/hora
- **Calidad:** Muy alta (stock photos profesionales)
- **API:** https://www.pexels.com/api/

### 3. Google Static Maps âœ…
- **Costo:** $0 hasta 28,000 llamadas/mes
- **Registro:** No requerido para tier gratuito
- **Uso:** Vistas aÃ©reas/satÃ©lite de ciudades
- **LimitaciÃ³n:** Sin street-level

### 4. Tus Propias Fotos âœ…
- **Costo:** $0
- **Calidad:** Depende de ti
- **Ventaja:** Control total, datos reales
- **Herramienta:** `manual_image_import.py`

---

## ğŸ’¡ Tips para Mejores Resultados

### Durante la MinerÃ­a:
1. **Prioriza ciudades con baja confianza** en tus tests iniciales
2. **Mezcla fuentes:** Wikimedia (histÃ³rico) + Pexels (moderno) + Google (aÃ©reo)
3. **Empieza con 5-10 ciudades** (no todas las 68 de golpe)

### Durante la AnotaciÃ³n:
1. âœ… **Marca solo imÃ¡genes de alta calidad**
   - Con landmarks visibles
   - Arquitectura caracterÃ­stica
   - Letreros legibles

2. âŒ **Evita anotar:**
   - ImÃ¡genes genÃ©ricas (podrÃ­an ser de cualquier lugar)
   - Fotos muy oscuras o borrosas
   - Close-ups sin contexto

3. â­ **Confianza alta (80-100%)** solo si:
   - Reconoces el lugar personalmente
   - Hay landmarks claramente identificables
   - El texto/letreros confirman la ubicaciÃ³n

### Durante el Fine-Tuning:
1. **Primera vez:** Usa default (5 Ã©pocas, batch 8)
2. **Si tienes GPU:** Aumenta batch-size a 16-32
3. **Si tienes 200+ imÃ¡genes:** Aumenta Ã©pocas a 10
4. **Filtros de calidad:**
   ```powershell
   # Solo imÃ¡genes de alta calidad con confianza 80%+
   python finetune_model.py --min-quality "Alta" --min-confidence 80
   ```

---

## ğŸš€ Workflow Completo Paso a Paso

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 1: RECOLECCIÃ“N DE DATOS (1-2 horas)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â”œâ”€â–º OpciÃ³n A: MinerÃ­a automÃ¡tica
  â”‚   python data_mining.py --mode all --images 5 --limit 10
  â”‚   
  â”œâ”€â–º OpciÃ³n B: Fotos propias
  â”‚   python manual_image_import.py --folder "mis_fotos" --city "..."
  â”‚
  â””â”€â–º Resultado: 50-200 imÃ¡genes en data/mining/images/

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 2: ANOTACIÃ“N MANUAL (30-60 minutos)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â”œâ”€â–º streamlit run annotation_tool.py
  â”‚   
  â”œâ”€â–º Para cada imagen:
  â”‚   â€¢ Â¿Es la ciudad correcta? âœ“ / âœ—
  â”‚   â€¢ Calidad: Muy baja â†’ Muy alta
  â”‚   â€¢ Elementos: landmarks, arquitectura, letreros...
  â”‚   â€¢ Confianza: 0-100%
  â”‚
  â””â”€â–º Resultado: 50-100+ anotaciones en data/mining/annotations.json

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 3: FINE-TUNING (15-30 minutos)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â”œâ”€â–º python finetune_model.py --epochs 5
  â”‚   â€¢ Carga anotaciones
  â”‚   â€¢ Entrena CLIP con tus datos
  â”‚   â€¢ Guarda checkpoints
  â”‚   
  â””â”€â–º Resultado: model/modelo_finetuned.pth

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 4: REGENERAR EMBEDDINGS (5 minutos)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â”œâ”€â–º Edita build_model.py (lÃ­nea ~13):
  â”‚   # Cambiar:
  â”‚   MODEL_NAME = "openai/clip-vit-large-patch14"
  â”‚   # Por:
  â”‚   # (comentar MODEL_NAME y descomentar lo siguiente)
  â”‚   BASE_MODEL_PATH = "model/modelo_finetuned.pth"
  â”‚   
  â”œâ”€â–º python build_model.py
  â”‚   
  â””â”€â–º Resultado: model/modelo.pth actualizado

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 5: PROBAR MEJORAS                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â”œâ”€â–º streamlit run Geolocalizador.py
  â”‚   
  â”œâ”€â–º Sube la misma imagen que antes
  â”‚   
  â””â”€â–º Compara:
      ANTES: Taxco 1.66%
      AHORA: Taxco 28%+ ğŸ‰
```

---

## ğŸ› ï¸ Troubleshooting

### "No tengo muchas imÃ¡genes"
**SoluciÃ³n:** Empieza con 30-50. El fine-tuning mejorarÃ¡ incluso con pocos datos.

### "Las descargas de Wikimedia fallan"
**SoluciÃ³n:** Normal, algunas queries no retornan imÃ¡genes. Prueba con:
```powershell
python data_mining.py --mode city --city "Guadalajara" --images 15
```

### "Pexels no retorna imÃ¡genes"
**SoluciÃ³n:** 
1. Verifica tu API key: `echo $env:PEXELS_API_KEY`
2. Algunas ciudades pequeÃ±as no tienen fotos en Pexels
3. Usa solo Wikimedia + tus fotos propias

### "El fine-tuning es muy lento"
**SoluciÃ³n:**
- Reduce batch-size: `--batch-size 4`
- Reduce Ã©pocas: `--epochs 3`
- En CPU, toma ~10 min con 50 imÃ¡genes

### "El modelo no mejora"
**Causas comunes:**
1. ImÃ¡genes de baja calidad â†’ Filtra: `--min-quality "Alta"`
2. Anotaciones inconsistentes â†’ Revisa tus criterios
3. Dataset muy pequeÃ±o â†’ Necesitas 50+ imÃ¡genes mÃ­nimo
4. No regeneraste embeddings â†’ `python build_model.py`

---

## ğŸ“ˆ Monitoreo de Progreso

Durante el fine-tuning, verÃ¡s:
```
Epoch 1/5
loss: 0.4523  âœ… (bueno: < 0.5)

Epoch 3/5
loss: 0.2341  ğŸ¯ (excelente: < 0.3)

âœ… Train Loss: 0.2145
âœ… Val Loss: 0.2890  (validaciÃ³n ligeramente mÃ¡s alta es normal)
â­ Mejor modelo guardado
```

**InterpretaciÃ³n:**
- Loss > 0.5: Modelo aprendiendo
- Loss 0.3-0.5: Buen progreso
- Loss < 0.3: Excelente convergencia
- Val Loss >> Train Loss: Posible overfitting (normal con datos pequeÃ±os)

---

## ğŸ“ Conceptos Clave

**CLIP:** Modelo que entiende similitud entre imÃ¡genes y texto  
**Embedding:** RepresentaciÃ³n numÃ©rica de una ciudad (768 nÃºmeros)  
**Fine-tuning:** Ajustar el modelo con tus datos especÃ­ficos  
**Temperatura:** Controla cuÃ¡n "confiado" es el modelo  
**State backoff:** Usa info del estado cuando la ciudad es ambigua

---

## âœ… Checklist Final

Antes de probar el modelo mejorado:

- [ ] âœ… Descargadas/importadas 50+ imÃ¡genes
- [ ] âœ… Anotadas 50+ imÃ¡genes (calidad media-alta)
- [ ] âœ… Ejecutado `python finetune_model.py`
- [ ] âœ… Visto "âœ… Modelo guardado: model/modelo_finetuned.pth"
- [ ] âœ… Modificado `build_model.py` para usar modelo fine-tuneado
- [ ] âœ… Ejecutado `python build_model.py`
- [ ] âœ… Visto "âœ… Guardado model/modelo.pth"
- [ ] âœ… Ejecutado `streamlit run Geolocalizador.py`

---

**ğŸ‰ Â¡Listo! Tu modelo ahora deberÃ­a tener 10-20x mÃ¡s confianza en las predicciones.**

Para dudas, revisa el README.md completo o los comentarios en el cÃ³digo.
