# ğŸ›°ï¸ GEOLOCALIZADOR OSINT - MÃ‰XICO

Sistema completo de geolocalizaciÃ³n de imÃ¡genes usando CLIP + OCR, 100% open source.

## ğŸ“‹ DescripciÃ³n

Herramienta OSINT para geolocalizar fotografÃ­as en MÃ©xico mediante:
- **CLIP (Vision Transformer)**: Modelo de IA para anÃ¡lisis visual
- **OCR (Tesseract)**: ExtracciÃ³n de texto en imÃ¡genes
- **Fine-tuning**: Mejora con datos anotados manualmente
- **Fuentes abiertas**: Wikimedia Commons, Wikipedia, Pexels

## ğŸ¯ Modelo Pre-entrenado (Google Drive)

Si deseas usar el modelo ya entrenado sin realizar fine-tuning, descÃ¡rgalo aquÃ­:

**ğŸ“¦ [Descargar Modelo Fine-tuned](https://drive.google.com/drive/folders/1SMQZTZ1U_prWongTUwaCTURtpvYMaG8x?usp=sharing)**

Incluye:
- `modelo.pth` - Embeddings de 68 ciudades mexicanas
- `modelo_finetuned.pth` - Modelo CLIP entrenado con 100+ anotaciones
- `checkpoints/` - Checkpoints de entrenamiento por Ã©poca

**Instrucciones:**
1. Descarga los archivos del Drive
2. ColÃ³calos en la carpeta `model/` de este proyecto
3. Ejecuta `streamlit run Geolocalizador.py`

## ğŸš€ Inicio RÃ¡pido

### 1. InstalaciÃ³n

```powershell
# Clonar repositorio
git clone https://github.com/EGarpxMaster/Geolocalization-OSINT.git
cd Geolocalization-OSINT

# Crear entorno virtual
python -m venv .venv
.\.venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Uso BÃ¡sico (Sin Fine-tuning)

```powershell
# Generar modelo base (si no existe model/modelo.pth)
python build_model.py

# Ejecutar interfaz OSINT
streamlit run Geolocalizador.py
```

Abre http://localhost:8501 y sube una imagen para geolocalizarla.

### 3. Workflow Completo (Con Fine-tuning)

#### **Paso 1: MinerÃ­a de ImÃ¡genes**

```powershell
# Minar todas las ciudades (68 ciudades Ã— 20 imÃ¡genes = 1,360)
python mining_pipeline.py --mode all --images 20

# Ver progreso
python mining_pipeline.py --check-progress

# Minar un estado especÃ­fico
python mining_pipeline.py --mode state --state "Jalisco" --images 10
```

**Tiempo estimado**: 2 horas para dataset completo

#### **Paso 2: AnotaciÃ³n Manual**

```powershell
# Abrir herramienta de anotaciÃ³n
python training_pipeline.py --annotate
```

- Abre http://localhost:8501
- Categoriza imÃ¡genes (calidad, elementos, confianza)
- **MÃ­nimo recomendado**: 100 imÃ¡genes anotadas
- Anotaciones guardadas en `data/mining/annotations.json`

#### **Paso 3: Fine-tuning**

```powershell
# Entrenar modelo (5 Ã©pocas, batch size 8)
python training_pipeline.py --train --epochs 5 --batch-size 8
```

**ParÃ¡metros opcionales**:
- `--min-quality 2`: Calidad mÃ­nima de imÃ¡genes (1-5)
- `--min-confidence 50`: Confianza mÃ­nima del anotador (0-100)
- `--learning-rate 1e-5`: Tasa de aprendizaje

**Tiempo estimado**: 15-30 minutos (CPU), 5-10 minutos (GPU)

#### **Paso 4: Regenerar Embeddings**

```powershell
# Generar embeddings con modelo mejorado
python training_pipeline.py --build-model
```

Esto actualiza `model/modelo.pth` con el modelo fine-tuned.

#### **Paso 5: Probar Mejoras**

```powershell
# Ejecutar interfaz con modelo mejorado
streamlit run Geolocalizador.py
```

**Mejora esperada**: 1-2% â†’ 15-40% de confianza

## ğŸ“ Estructura del Proyecto

```
Geolocalization-OSINT/
â”œâ”€â”€ ğŸ“„ Archivos principales (ESENCIALES)
â”‚   â”œâ”€â”€ Geolocalizador.py           # Interfaz OSINT principal
â”‚   â”œâ”€â”€ mining_pipeline.py          # MinerÃ­a de imÃ¡genes
â”‚   â”œâ”€â”€ training_pipeline.py        # AnotaciÃ³n + Fine-tuning
â”‚   â”œâ”€â”€ build_model.py              # Generador de embeddings base
â”‚   â”œâ”€â”€ requirements.txt            # Dependencias Python
â”‚   â””â”€â”€ README.md                   # Esta documentaciÃ³n
â”‚
â”œâ”€â”€ ğŸ“Š Datos
â”‚   â”œâ”€â”€ data/cities_mx.csv          # 68 ciudades de MÃ©xico
â”‚   â””â”€â”€ data/mining/                # Datos de minerÃ­a
â”‚       â”œâ”€â”€ images/                 # ImÃ¡genes descargadas
â”‚       â”œâ”€â”€ metadata.json           # Metadata de imÃ¡genes
â”‚       â””â”€â”€ annotations.json        # Anotaciones manuales (Supabase)
â”‚
â”œâ”€â”€ ğŸ¤– Modelos (Descargar desde Google Drive)
â”‚   â”œâ”€â”€ model/modelo.pth            # Embeddings de ciudades
â”‚   â”œâ”€â”€ model/modelo_finetuned.pth  # Modelo CLIP fine-tuned
â”‚   â””â”€â”€ model/checkpoints/          # Checkpoints de entrenamiento
â”‚
â”œâ”€â”€ ğŸ”§ Scripts opcionales (Supabase)
â”‚   â”œâ”€â”€ supabase_client.py          # Cliente de Supabase
â”‚   â”œâ”€â”€ upload_annotations_to_supabase.py
â”‚   â”œâ”€â”€ download_annotations_from_supabase.py
â”‚   â”œâ”€â”€ fix_annotations_image_id.py
â”‚   â””â”€â”€ clean_orphan_annotations.py
â”‚
â””â”€â”€ ğŸ“¸ Extras
    â””â”€â”€ photos/                     # Fotos de prueba
```

### Archivos esenciales (mÃ­nimo para funcionar):
- `Geolocalizador.py` - Interfaz principal
- `build_model.py` - Generar modelo base
- `requirements.txt` - Instalar dependencias
- `data/cities_mx.csv` - Lista de ciudades
- `model/modelo.pth` - [Descargar del Drive](https://drive.google.com/drive/folders/1SMQZTZ1U_prWongTUwaCTURtpvYMaG8x?usp=sharing)

### Archivos opcionales (para fine-tuning):
- `mining_pipeline.py` - Solo si quieres minar mÃ¡s imÃ¡genes
- `training_pipeline.py` - Solo si quieres entrenar
- Scripts de Supabase - Solo si usas base de datos cloud

## ğŸ”§ ConfiguraciÃ³n Avanzada

### MinerÃ­a Personalizada

```powershell
# Minar ciudad especÃ­fica
python mining_pipeline.py --mode city --city "Guadalajara" --images 30

# Ver estadÃ­sticas detalladas
python mining_pipeline.py --check-progress
```

**Nombres de archivos optimizados:**
El sistema genera nombres Ãºnicos automÃ¡ticamente:
```
{fuente}_{ciudad}_{estado}_{Ã­ndice}_{timestamp}.jpg
Ejemplo: wikimedia_Guadalajara_Jalisco_5_1732901234.jpg
```

Esto previene:
- âœ… Conflictos por duplicados
- âœ… Sobrescrituras accidentales
- âœ… Problemas con caracteres especiales (sanitizados automÃ¡ticamente)

### Fine-tuning Personalizado

```powershell
# Entrenamiento intensivo (mÃ¡s Ã©pocas)
python training_pipeline.py --train --epochs 10 --batch-size 4 --learning-rate 5e-6

# Filtros mÃ¡s estrictos
python training_pipeline.py --train --min-quality 4 --min-confidence 80
```

### OptimizaciÃ³n de Memoria

El sistema estÃ¡ optimizado para usar mÃ­nima memoria:

- **Carga lazy**: Recursos se cargan solo cuando se necesitan
- **Cache de Streamlit**: Modelo se carga 1 sola vez
- **LiberaciÃ³n explÃ­cita**: GPU memory se libera despuÃ©s de cada inferencia
- **Modo eval**: Desactiva gradientes en inferencia (reduce memoria 50%)

**Memoria requerida**:
- Inferencia bÃ¡sica: ~2 GB RAM, ~1 GB VRAM (GPU)
- Fine-tuning: ~8 GB RAM, ~4 GB VRAM (recomendado)

## ğŸŒ Fuentes de Datos (100% Gratuitas)

### 1. Wikimedia Commons
- **API**: Ilimitada, sin autenticaciÃ³n
- **Calidad**: Alta, imÃ¡genes de Wikipedia
- **Cobertura**: Excelente para monumentos y lugares turÃ­sticos

### 2. Wikipedia
- **API**: MediaWiki API, gratuita
- **Calidad**: Variable, pero contextualmente relevante
- **Cobertura**: Buena para artÃ­culos de ciudades

### 3. Pexels
- **API**: Gratuita con registro (2 min)
- **LÃ­mite**: 200 requests/hora
- **Calidad**: Profesional, fotos stock

**Clave API Pexels**: Ya incluida en `mining_pipeline.py`

## ğŸ“Š Resultados Esperados

### Antes del Fine-tuning
```
Taxco de AlarcÃ³n, Guerrero     â€” 1.66%
Cuernavaca, Morelos           â€” 1.60%
San Miguel de Allende, Gto    â€” 1.59%
```

### DespuÃ©s del Fine-tuning (100+ anotaciones)
```
Taxco de AlarcÃ³n, Guerrero     â€” 24.3%
Cuernavaca, Morelos           â€” 18.7%
San Miguel de Allende, Gto    â€” 15.2%
```

**Mejora tÃ­pica**: 10-20x en confianza

## ğŸ› Troubleshooting

### Problema: "KeyError: 'city_embeds'"
**SoluciÃ³n**: Regenera el modelo
```powershell
python build_model.py
```

### Problema: OCR no funciona
**SoluciÃ³n**: Instala Tesseract
```powershell
# Descargar desde: https://github.com/UB-Mannheim/tesseract/wiki
# Instalar en: C:\Program Files\Tesseract-OCR
```

### Problema: "CUDA out of memory"
**SoluciÃ³n**: Reduce batch size o usa CPU
```powershell
python training_pipeline.py --train --batch-size 4
```

### Problema: MinerÃ­a muy lenta
**SoluciÃ³n**: Usa menos imÃ¡genes o un estado especÃ­fico
```powershell
python mining_pipeline.py --mode state --state "CDMX" --images 10
```

### Problema: Pocas imÃ¡genes descargadas
**Causas comunes**:
- Pexels rate limit (200/hora) â†’ Espera 1 hora
- Ciudad muy especÃ­fica â†’ Prueba ciudad mÃ¡s grande
- Problemas de red â†’ Verifica conexiÃ³n

## ğŸ¯ Tips para Mejores Resultados

### AnotaciÃ³n
1. **Calidad > Cantidad**: 100 buenas anotaciones > 500 malas
2. **Prioriza elementos Ãºnicos**: Monumentos, arquitectura caracterÃ­stica
3. **SÃ© consistente**: Usa los mismos criterios siempre
4. **Verifica la ciudad**: Solo marca "SÃ­" si estÃ¡s seguro

### Fine-tuning
1. **Empieza pequeÃ±o**: 5 Ã©pocas, luego aumenta si mejora
2. **Monitorea val_loss**: Si sube, hay overfitting
3. **Usa checkpoints**: Guarda cada Ã©poca para comparar
4. **Dataset balanceado**: Similar cantidad de imÃ¡genes por estado

### Inferencia
1. **Ajusta temperatura**: Menor = mÃ¡s confianza, Mayor = mÃ¡s diversidad
2. **Backoff por estado**: Ãštil para ciudades desconocidas
3. **OCR boost**: Aumenta si hay letreros visibles
4. **Prueba mÃºltiples fotos**: Combina resultados mentalmente

## ğŸ“š Arquitectura TÃ©cnica

### Modelo Base
- **CLIP**: `openai/clip-vit-large-patch14`
- **DimensiÃ³n**: 768D embeddings
- **NormalizaciÃ³n**: Cosine similarity
- **Temperatura**: Softmax scaling (0.1-2.0)

### Fine-tuning
- **Loss**: Contrastive loss bidireccional (imagenâ†’texto, textoâ†’imagen)
- **Optimizador**: AdamW
- **Learning rate**: 1e-5 (default)
- **Data augmentation**: Multi-prompt per city (12 prompts)

### OCR Boost
- **Engine**: Tesseract 5.x
- **Idiomas**: spa+eng
- **Preprocesamiento**: Bilateral filter + grayscale
- **Boost**: +15% ciudad, +5% estado (configurable)

### Backoff por Estado
```python
score_final = (1 - Î±) * score_ciudad + Î± * score_estado
```
donde Î± = 0.25 (configurable)

## ğŸ” Privacidad y OSINT

Este proyecto es **100% open source** y **no requiere APIs pagas**:
- âœ… Sin tracking
- âœ… Sin telemetrÃ­a
- âœ… Datos procesados localmente
- âœ… Fuentes pÃºblicas y abiertas
- âœ… Compatible con investigaciÃ³n OSINT Ã©tica

## ğŸ“„ Licencia

MIT License - Uso libre para fines educativos y de investigaciÃ³n OSINT.

## ğŸ™ CrÃ©ditos

- **CLIP**: OpenAI
- **Tesseract**: Google
- **Streamlit**: Streamlit Inc.
- **Wikimedia Commons**: Wikimedia Foundation
- **Pexels**: Pexels.com

## ğŸ“ Soporte

Si encuentras errores o tienes sugerencias:
1. Revisa la secciÃ³n **Troubleshooting**
2. Verifica que usaste los comandos correctos
3. Abre un issue en GitHub con detalles completos

---

**VersiÃ³n**: 2.0 (Unificada y Optimizada)
**Ãšltima actualizaciÃ³n**: Noviembre 2025
